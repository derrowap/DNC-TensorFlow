DNA sequencing methods first starting publishing in 1975 \cite{SANGER1975441}.
In 1977, the Sanger method was shown to be the fastest and most accurate
way to sequence DNA at the time \cite{sanger1977dna}. Since then, the
Human Genome Project (HGP) has started with the goal of sequencing and mapping
the entire human genome \cite{international2001initial}. The HGP helps
accelerate biomedical research by providing a mass amount of data
that can be used to locate disease genes, identify drug targets, or even
research other physiology and cell biology applications
\cite{international2001initial}. In summary, DNA sequencing is not only
beneficial for research purposes, but also beneficial for clinical purposes.

MinION is a USB memory stick sized device from Oxford Nanopore Technologies
costing approximately \$1000 and produces DNA sequence data using nanopores.
The nanopores produce signals which we can segment into groups. Base-calling
algorithms classify these groups into nucleotides (\textit{A}, \textit{G},
\textit{C}, or \textit{T}). As DNA fragments are fed through the device,
a drop in electrical current occurs depending on the nucleotide in the
nanopore. These drops in electrical current are recorded in a series of
signals. A base-caller algorithm then must read these recorded signals and
produce the corresponding DNA sequence.

The base-caller, DeepNano, is built using a recurrent neural network and has
been found to perform more accurately than the default base caller supplied
by the manufacturer \cite{bovza2017deepnano}. DeepNano achieved 77.9\% accuracy
on an \textit{E. coli} dataset and 76.3\% accuracy on a \textit{K. pneumoniae}
dataset \cite{bovza2017deepnano}. The default base caller, Metrichor, only
achieved 71.3\% accuracy on the \textit{E. coli} dataset and 68.1\% accuracy on
the \textit{K. pneumoniae} dataset \cite{bovza2017deepnano}.

We test the performance of the DNC as a base caller on a MinION dataset
provided by Ryan Poplin on the Google Brain team. The dataset consists of a
\texttt{train.hdf5} file with size 2.9 GB and a \texttt{val.hdf5} file with
size 1.16 GB. Each file has multiple hdf5 groups representing a run of the
MinION device. A group in one of the hdf5 files has both a \quotes{label} and a
\quotes{signal} dataset. The \quotes{signal} dataset contains the signals
generated by the MinION device. The \quotes{label} dataset is a collection
of triples \mbox{(\quotes{start index}, \quotes{end index}, \quotes{base})}.
The signals at indices \mbox{[\quotes{start index}, \quotes{end index}]} are
labelled as the nucleotide \quotes{base}.

We used an LSTM as a baseline model to compare performance on the dataset with
the DNC. We tested four different LSTM models differing on the number of units
used. Table \ref{tab:table3_1} shows the results of the LSTM baseline models.
The best LSTM performance on the validation dataset was with X many units.
The testing accuracy for the model with X many units is reported on a dataset
of size X from the \texttt{val.hdf5} file (0.00\%).

\begin{table}[h!]
\begin{center}
\begin{tabular}{ | c || c | c | }
 \hline
 \multicolumn{3}{|c|}{\bf{LSTM Baseline Model Performances}} \\
 \hline
 Number of Units & Training Accuracy & Validation Accuracy \\
 \hline
 128  & 0.00\% & 0.00\% \\
 512  & 0.00\% & 0.00\% \\
 1024 & 0.00\% & 0.00\% \\
 2048 & 0.00\% & 0.00\% \\
 \hline
\end{tabular}
\caption{
    All LSTM models were trained on a dataset with size X from
    the \texttt{train.hdf5} file. Each model trained for X many training
    iterations. Accuracy is defined as the number of correctly labeled
    nucleotides divided by the number of total nucleotides labelled. Validation
    accuracy is reported on a validation set of size X from the
    \texttt{train.hdf5} file.
}
\label{tab:table3_1}
\end{center}
\end{table}

The DNC was trained on the same datasets as the LSTM baseline models. A subset
of the total grid search method was used for hyperparameter optimization.
Results for the five best trained models are shown in Table \ref{tab:table3_2}.
Training the best performing DNC model for an additional 50,000 steps resulted
in a training accuracy of 85\% and a validation accuracy of 37\%. This is
almost the same as when the model was only trained with 100,000 iterations and
thus we can conclude training longer will not result in any improvements.

\begin{table}[h!]
\begin{center}
\begin{tabular}{ | c | c | c || P{2cm} | P{2cm} | }
 \hline
 \multicolumn{5}{|c|}{\bf{DNC Performance on DNA Sequencing}} \\
 \hline
 Read Heads & Memory Size & Word Size & Training Accuracy & Validation Accuracy \\
 \hline
 4  & 16 & 4  & \bf{90\%} & \bf{38\%} \\
 16 & 128& 64 & 35\% & 37\% \\
 1  & 8  & 1  & 46\% & 32\% \\
 1  & 32 & 16 & 33\% & 27\% \\
 8  & 32 & 16 & 27\% & 26\% \\
 \hline
\end{tabular}
\caption{
    \textbf{Table 3.2:} All DNC models were trained on a dataset with size 100
    from the \texttt{train.hdf5} file. Each model trained for 100000 many
    training iterations. Accuracy is defined as the number of correctly labeled
    nucleotides divided by the number of total nucleotides labelled. Validation
    accuracy is reported on a validation set of size 10000 from the
    \texttt{train.hdf5} file.
}
\label{tab:table3_2}
\end{center}
\end{table}

Using a training dataset size of 10000, we trained a DNC model with the same
hyperparameters as the best performing model in Table \ref{tab:table3_2}:
four read heads, memory size of sixteen, word size of four. After 100000
training iterations, the model was performing with a training accuracy of
53\% and a validation accuracy of 29\%. After training an additional 50000
iterations, the training accuracy went down to 51\% and the validation
accuracy went to 30\%. Due to the difference in validation accuracy being only
1\% and the training accuracy decreasing, we conclude further training the
model would result in no further significant improvements. The DNC model
performed with greater accuracy when trained with only 100 examples.

We have found that the DNC model is unable to perform DNA sequencing on
nanopore reads at the accuracy of other available software as described
previously. Future research may reveal that a different subset of training data
and a different configuration of hyperparameters yields a better performing
DNC on the task.
